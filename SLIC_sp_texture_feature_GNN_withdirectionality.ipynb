{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57a57c9c",
   "metadata": {},
   "source": [
    "Malignant Melanocytic Proliferation detector through Super-Pixel Texture Feature Graph Neural Network\n",
    "\n",
    "SLIC Superpixel Model Interactive Python Notebook\n",
    "\n",
    "Keith Miller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d16316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from trainingImageLoader import ImageLoader\n",
    "import mahotas as mh\n",
    "import cv2\n",
    "from skimage.util import img_as_ubyte\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch_geometric.utils as pyg_utils\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import SLIC_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96795cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_DISTANCE = 10\n",
    "SUPERPIXEL_COUNT = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23d569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ISIC_0000000.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "1\n",
      "ISIC_0000001.jpg\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "training_data_list = []\n",
    "training_folder_ = 'ISIC-2017-training' # Image folder path (I used the ISIC folders directly from ISIC website)\n",
    "training_metadata_ = 'challenge-2017-training_metadata.csv' # metadata csv file path (metadata cvs file provided with ISIC dataset)\n",
    "training_data_loader = ImageLoader(training_folder_)\n",
    "training_data_loader.load_metadata(training_metadata_)\n",
    "for i in range(training_data_loader.num_images):\n",
    "    image_, class_ = training_data_loader.iterate(return_type=cv2.IMREAD_COLOR)\n",
    "    haralick_features = []\n",
    "    '''\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(image_.shape[1] * scale_percent / 100)\n",
    "    height = int(image_.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    image_ = cv2.resize(image_, dim, interpolation = cv2.INTER_AREA)\n",
    "    '''\n",
    "    segments_, adjacency_matrix = SLIC_graph.slic_graph(image_, SUPERPIXEL_COUNT, 10)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image_, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for label in range(SUPERPIXEL_COUNT):\n",
    "        mask = (segments_ == label)\n",
    "        patch = gray_image * mask\n",
    "        patch_cropped = patch[mask]\n",
    "\n",
    "        if len(patch_cropped) == 0:\n",
    "             feats = np.zeros(26)  # default zero vector for empty patches\n",
    "        else:\n",
    "            try: #there are a couple of images that give errors, I need to kick them out, but for now I am using a try/except block\n",
    "                feats_mean = mh.features.haralick(patch, ignore_zeros=True, distance=PIXEL_DISTANCE).mean(axis=0)\n",
    "                feats_max = mh.features.haralick(patch, ignore_zeros=True, distance=PIXEL_DISTANCE).max(axis=0)\n",
    "                feats = np.concat(feats_mean, feats_max, axis = 1)\n",
    "            except:\n",
    "                feats = np.zeros(26)\n",
    "\n",
    "        haralick_features.append(feats)\n",
    "    haralick_features = np.array(haralick_features)\n",
    "\n",
    "    edge_index = pyg_utils.dense_to_sparse(torch.tensor(adjacency_matrix))[0]\n",
    "    data = Data(x=torch.tensor(haralick_features, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                y=torch.tensor([class_], dtype=torch.long))  # label is 0 or 1\n",
    "\n",
    "    # Add to dataset\n",
    "    training_data_list.append(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a173218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of           isic_id attribution copyright_license  age_approx  \\\n",
      "0    ISIC_0001769   Anonymous              CC-0        15.0   \n",
      "1    ISIC_0001852   Anonymous              CC-0        10.0   \n",
      "2    ISIC_0001871   Anonymous              CC-0        15.0   \n",
      "3    ISIC_0003462   Anonymous              CC-0        15.0   \n",
      "4    ISIC_0003539   Anonymous              CC-0        15.0   \n",
      "..            ...         ...               ...         ...   \n",
      "145  ISIC_0015443   Anonymous              CC-0        50.0   \n",
      "146  ISIC_0015445   Anonymous              CC-0        50.0   \n",
      "147  ISIC_0015483   Anonymous              CC-0        50.0   \n",
      "148  ISIC_0015496   Anonymous              CC-0        20.0   \n",
      "149  ISIC_0015627   Anonymous              CC-0        15.0   \n",
      "\n",
      "    anatom_site_general anatom_site_special benign_malignant  \\\n",
      "0                   NaN                 NaN           benign   \n",
      "1                   NaN                 NaN           benign   \n",
      "2                   NaN                 NaN           benign   \n",
      "3                   NaN                 NaN           benign   \n",
      "4                   NaN                 NaN           benign   \n",
      "..                  ...                 ...              ...   \n",
      "145     upper extremity                 NaN           benign   \n",
      "146     lower extremity           acral NOS           benign   \n",
      "147      anterior torso                 NaN           benign   \n",
      "148     posterior torso                 NaN           benign   \n",
      "149       lateral torso                 NaN           benign   \n",
      "\n",
      "     clin_size_long_diam_mm  concomitant_biopsy       dermoscopic_type  ...  \\\n",
      "0                       NaN               False                    NaN  ...   \n",
      "1                       NaN               False                    NaN  ...   \n",
      "2                       NaN               False                    NaN  ...   \n",
      "3                       NaN               False                    NaN  ...   \n",
      "4                       NaN               False                    NaN  ...   \n",
      "..                      ...                 ...                    ...  ...   \n",
      "145                     NaN                True  contact non-polarized  ...   \n",
      "146                     NaN                True  contact non-polarized  ...   \n",
      "147                     NaN                True  contact non-polarized  ...   \n",
      "148                     NaN                True  contact non-polarized  ...   \n",
      "149                     NaN                True  contact non-polarized  ...   \n",
      "\n",
      "           diagnosis_5         diagnosis_confirm_type family_hx_mm  \\\n",
      "0                  NaN  single image expert consensus          NaN   \n",
      "1                  NaN  single image expert consensus          NaN   \n",
      "2                  NaN  single image expert consensus          NaN   \n",
      "3                  NaN  single image expert consensus          NaN   \n",
      "4                  NaN  single image expert consensus          NaN   \n",
      "..                 ...                            ...          ...   \n",
      "145                NaN                 histopathology          NaN   \n",
      "146  Nevus, Dysplastic                 histopathology          NaN   \n",
      "147                NaN                 histopathology          NaN   \n",
      "148  Nevus, Dysplastic                 histopathology          NaN   \n",
      "149                NaN                 histopathology          NaN   \n",
      "\n",
      "      image_type   lesion_id melanocytic nevus_type  patient_id  \\\n",
      "0    dermoscopic         NaN        True        NaN         NaN   \n",
      "1    dermoscopic         NaN        True        NaN         NaN   \n",
      "2    dermoscopic         NaN        True        NaN         NaN   \n",
      "3    dermoscopic         NaN        True        NaN         NaN   \n",
      "4    dermoscopic         NaN        True        NaN         NaN   \n",
      "..           ...         ...         ...        ...         ...   \n",
      "145  dermoscopic  IL_4373176        True        NaN  IP_7503857   \n",
      "146  dermoscopic  IL_3061261        True        NaN  IP_8583946   \n",
      "147  dermoscopic  IL_2190859        True        NaN  IP_6108028   \n",
      "148  dermoscopic  IL_3374880        True        NaN  IP_4491986   \n",
      "149  dermoscopic  IL_8315691        True        NaN  IP_0532448   \n",
      "\n",
      "    personal_hx_mm     sex  \n",
      "0              NaN  female  \n",
      "1              NaN  female  \n",
      "2              NaN    male  \n",
      "3              NaN  female  \n",
      "4              NaN  female  \n",
      "..             ...     ...  \n",
      "145            NaN  female  \n",
      "146            NaN  female  \n",
      "147            NaN    male  \n",
      "148            NaN  female  \n",
      "149            NaN  female  \n",
      "\n",
      "[150 rows x 24 columns]>\n"
     ]
    }
   ],
   "source": [
    "test_data_list = []\n",
    "test_folder_ = 'ISIC-images_2017_test' # Image folder path (I used the ISIC folders directly from ISIC website)\n",
    "test_metadata_ = 'challenge-2017-test_metadata.csv' # metadata csv file path (metadata cvs file provided with ISIC dataset)\n",
    "test_data_loader = ImageLoader(test_folder_)\n",
    "test_data_loader.load_metadata(test_metadata_)\n",
    "for i in range(test_data_loader.num_images):\n",
    "    image_, class_ = test_data_loader.iterate(cv2.IMREAD_COLOR_RGB)\n",
    "    haralick_features = []\n",
    "    '''\n",
    "    scale_percent = 50 # percent of original size\n",
    "    width = int(image_.shape[1] * scale_percent / 100)\n",
    "    height = int(image_.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    image_ = cv2.resize(image_, dim, interpolation = cv2.INTER_AREA)\n",
    "    '''\n",
    "    segments_, adjacency_matrix = SLIC_graph.slic_graph(image_, SUPERPIXEL_COUNT, 10)\n",
    "\n",
    "    gray_image = cv2.cvtColor(image_, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    for label in range(SUPERPIXEL_COUNT):\n",
    "        mask = (segments_ == label)\n",
    "        patch = gray_image * mask\n",
    "        patch_cropped = patch[mask]\n",
    "\n",
    "        if len(patch_cropped) == 0:\n",
    "            feats = np.zeros(26)  # default zero vector for empty patches\n",
    "        else:\n",
    "            try: #there are a couple of images that give errors, I need to kick them out, but for now I am using a try/except block\n",
    "            # Compute Haralick features and take mean over directions\n",
    "                feats_mean = mh.features.haralick(patch, ignore_zeros=True, distance=PIXEL_DISTANCE).mean(axis=0)\n",
    "                feats_max = mh.features.haralick(patch, ignore_zeros=True, distance=PIXEL_DISTANCE).max(axis=0)\n",
    "                feats = np.concat(feats_mean, feats_max, axis = 1)\n",
    "            except:\n",
    "                feats = np.zeros(26)\n",
    "\n",
    "        haralick_features.append(feats)\n",
    "    haralick_features = np.array(haralick_features)\n",
    "\n",
    "    edge_index = pyg_utils.dense_to_sparse(torch.tensor(adjacency_matrix))[0]\n",
    "    data = Data(x=torch.tensor(haralick_features, dtype=torch.float),\n",
    "                edge_index=edge_index,\n",
    "                y=torch.tensor([class_], dtype=torch.long))  # label is 0 or 1\n",
    "\n",
    "    # Add to dataset\n",
    "    test_data_list.append(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f230735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Avg Loss: 17.1356\n",
      "Epoch 2, Avg Loss: 3.1339\n",
      "Epoch 3, Avg Loss: 0.8737\n",
      "Epoch 4, Avg Loss: 0.5386\n",
      "Epoch 5, Avg Loss: 0.5204\n",
      "Epoch 6, Avg Loss: 0.5102\n",
      "Epoch 7, Avg Loss: 0.5215\n",
      "Epoch 8, Avg Loss: 0.6076\n",
      "Epoch 9, Avg Loss: 0.5310\n",
      "Epoch 10, Avg Loss: 0.4998\n",
      "Epoch 11, Avg Loss: 0.5279\n",
      "Epoch 12, Avg Loss: 0.5228\n",
      "Epoch 13, Avg Loss: 0.5482\n",
      "Epoch 14, Avg Loss: 0.5427\n",
      "Epoch 15, Avg Loss: 0.5003\n",
      "Epoch 16, Avg Loss: 0.5435\n",
      "Epoch 17, Avg Loss: 0.5216\n",
      "Epoch 18, Avg Loss: 0.5068\n",
      "Epoch 19, Avg Loss: 0.4899\n",
      "Epoch 20, Avg Loss: 0.4888\n",
      "Epoch 21, Avg Loss: 0.5062\n",
      "Epoch 22, Avg Loss: 0.4875\n",
      "Epoch 23, Avg Loss: 0.4977\n",
      "Epoch 24, Avg Loss: 0.5047\n",
      "Epoch 25, Avg Loss: 0.4942\n",
      "Epoch 26, Avg Loss: 0.4996\n",
      "Epoch 27, Avg Loss: 0.4972\n",
      "Epoch 28, Avg Loss: 0.5037\n",
      "Epoch 29, Avg Loss: 0.4886\n",
      "Epoch 30, Avg Loss: 0.4958\n",
      "Epoch 31, Avg Loss: 0.4911\n",
      "Epoch 32, Avg Loss: 0.5055\n",
      "Epoch 33, Avg Loss: 0.5201\n",
      "Epoch 34, Avg Loss: 0.4976\n",
      "Epoch 35, Avg Loss: 0.4915\n",
      "Epoch 36, Avg Loss: 0.4874\n",
      "Epoch 37, Avg Loss: 0.4980\n",
      "Epoch 38, Avg Loss: 0.4941\n",
      "Epoch 39, Avg Loss: 0.4864\n",
      "Epoch 40, Avg Loss: 0.4885\n",
      "Epoch 41, Avg Loss: 0.4876\n",
      "Epoch 42, Avg Loss: 0.4894\n",
      "Epoch 43, Avg Loss: 0.4879\n",
      "Epoch 44, Avg Loss: 0.4855\n",
      "Epoch 45, Avg Loss: 0.4879\n",
      "Epoch 46, Avg Loss: 0.4857\n",
      "Epoch 47, Avg Loss: 0.4907\n",
      "Epoch 48, Avg Loss: 0.4877\n",
      "Epoch 49, Avg Loss: 0.4847\n",
      "Epoch 50, Avg Loss: 0.4962\n"
     ]
    }
   ],
   "source": [
    "#going to be 120%, I don't understand what's going on here \n",
    "\n",
    "# GNN model definition\n",
    "class GridGNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes=2):\n",
    "        super(GridGNNClassifier, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = global_mean_pool(x, batch)  # Corrected pooling\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# Instantiate model\n",
    "model = GridGNNClassifier(num_features=13, hidden_channels=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# DataLoader for batching (e.g., batch size = 32)\n",
    "loader = DataLoader(training_data_list, batch_size=128, shuffle=True)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(500):\n",
    "    total_loss = 0\n",
    "    for batch_data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch_data.x, batch_data.edge_index, batch_data.batch)\n",
    "        loss = F.nll_loss(out, batch_data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    print(f'Epoch {epoch+1}, Avg Loss: {avg_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53399a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loader = DataLoader(test_data_list, batch_size=100)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for batch_data in test_loader:\n",
    "    preds = model(batch_data.x, batch_data.edge_index, batch_data.batch).argmax(dim=1)\n",
    "    correct += (preds == batch_data.y).sum().item()\n",
    "    total += batch_data.y.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
